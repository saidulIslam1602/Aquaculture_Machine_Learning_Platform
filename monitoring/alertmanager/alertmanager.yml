# =============================================================================
# ALERTMANAGER CONFIGURATION - AQUACULTURE PLATFORM NOTIFICATION SYSTEM
# =============================================================================
#
# WHAT IS THIS FILE?
# This file configures Alertmanager, the notification system that receives
# alerts from Prometheus and sends them to the right people through the right
# channels. Think of it as the "emergency dispatcher" for the platform.
#
# WHAT IS ALERTMANAGER?
# Alertmanager is like a "smart notification system" that:
# - Receives alerts from Prometheus when problems are detected
# - Decides who should be notified based on the type of problem
# - Sends notifications through multiple channels (email, Slack, PagerDuty)
# - Groups similar alerts together to avoid spam
# - Silences alerts during maintenance windows
# - Escalates alerts if they're not acknowledged
#
# HOW ALERTMANAGER WORKS:
# 1. Prometheus sends alerts to Alertmanager when rules are triggered
# 2. Alertmanager groups similar alerts together (e.g., all API errors)
# 3. Routes alerts to appropriate teams based on severity and component
# 4. Sends notifications through configured channels
# 5. Tracks alert lifecycle (firing, resolved, silenced)
#
# KEY CONCEPTS FOR BEGINNERS:
# - Route: Rules that determine where alerts go based on labels
# - Receiver: A destination for alerts (email, Slack channel, PagerDuty)
# - Grouping: Combining similar alerts to reduce notification noise
# - Inhibition: Suppressing alerts when related higher-priority alerts are active
# - Silencing: Temporarily stopping alerts during maintenance
#
# AUTHOR: DevOps Team
# VERSION: 1.0.0
# UPDATED: 2024-10-26
# =============================================================================

# =============================================================================
# GLOBAL CONFIGURATION - NOTIFICATION SETTINGS
# =============================================================================
# These settings apply to all notification channels

global:
  # Email configuration for sending alert notifications
  smtp_smarthost: 'smtp.gmail.com:587'                    # Gmail SMTP server
  smtp_from: 'alerts@aquaculture-platform.com'           # Sender email address
  smtp_auth_username: 'alerts@aquaculture-platform.com'  # SMTP authentication username
  smtp_auth_password: 'your-app-password'                 # SMTP authentication password (use app password for Gmail)
  smtp_require_tls: true                                  # Use encrypted connection

  # Slack configuration for team notifications
  slack_api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'  # Slack webhook URL

  # PagerDuty configuration for critical incident management
  pagerduty_url: 'https://events.pagerduty.com/v2/enqueue'  # PagerDuty API endpoint

  # Default time to wait before considering an alert resolved if no updates received
  resolve_timeout: 5m

# Templates for alert notifications
templates:
  - '/etc/alertmanager/templates/*.tmpl'

# Routing configuration
route:
  group_by: ['alertname', 'cluster', 'service', 'severity']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h
  receiver: 'default'
  
  routes:
    # Critical alerts - immediate notification to all channels
    - match:
        severity: critical
      receiver: 'critical-alerts'
      group_wait: 0s
      repeat_interval: 5m
      continue: true
      
    # Security alerts - immediate security team notification
    - match:
        component: security
      receiver: 'security-team'
      group_wait: 0s
      repeat_interval: 15m
      group_by: ['alertname', 'attack_type', 'source_ip']
      continue: true
      
    # API alerts - platform team
    - match:
        component: api
      receiver: 'platform-team'
      group_by: ['alertname', 'endpoint', 'status']
      routes:
        # High priority API alerts
        - match:
            severity: critical
          receiver: 'platform-team-urgent'
          repeat_interval: 5m
      
    # ML/AI alerts - ML operations team
    - match:
        component: ml
      receiver: 'ml-ops-team'
      group_by: ['alertname', 'model', 'model_type']
      routes:
        # Model performance degradation
        - match_re:
            alertname: '.*Accuracy.*|.*Drift.*'
          receiver: 'ml-ops-team-models'
          repeat_interval: 30m
        # ML infrastructure issues
        - match_re:
            alertname: '.*Service.*|.*Latency.*'
          receiver: 'ml-ops-team-infra'
          repeat_interval: 10m
      
    # Business alerts - operations team
    - match:
        component: business
      receiver: 'operations-team'
      group_by: ['alertname', 'kpi', 'tank_id']
      routes:
        # Critical business alerts (mortality, compliance)
        - match_re:
            alertname: '.*Mortality.*|.*Compliance.*'
          receiver: 'operations-team-urgent'
          repeat_interval: 15m
        # Production and efficiency alerts
        - match_re:
            alertname: '.*Production.*|.*Efficiency.*'
          receiver: 'operations-team-production'
          repeat_interval: 1h
      
    # Infrastructure alerts - platform team
    - match:
        component: infrastructure
      receiver: 'platform-team-infra'
      group_by: ['alertname', 'instance', 'device']
      routes:
        # Database alerts
        - match_re:
            alertname: '.*PostgreSQL.*|.*Redis.*'
          receiver: 'database-team'
          repeat_interval: 10m
        # Container and Kubernetes alerts
        - match_re:
            alertname: '.*Container.*|.*Pod.*|.*Kubernetes.*'
          receiver: 'platform-team-k8s'
          repeat_interval: 15m
      
    # SLA alerts - management and platform team
    - match:
        component: sla
      receiver: 'sla-management'
      group_by: ['alertname', 'sla_type']
      repeat_interval: 30m
      continue: true
      
    # Maintenance window - suppress non-critical alerts
    - match:
        maintenance: 'true'
      receiver: 'null'
      group_wait: 0s

# Inhibition rules to reduce alert noise
inhibit_rules:
  # If API is down, don't alert on high response times
  - source_match:
      alertname: 'APIDown'
    target_match:
      component: 'api'
    target_match_re:
      alertname: '.*Latency.*|.*ResponseTime.*'
    equal: ['job', 'instance']

  # If ML service is down, don't alert on model performance
  - source_match:
      alertname: 'MLServiceDown'
    target_match:
      component: 'ml'
    target_match_re:
      alertname: '.*Accuracy.*|.*Latency.*'
    equal: ['job', 'instance']

  # If database is down, don't alert on connection errors
  - source_match_re:
      alertname: '.*Down'
      component: 'database'
    target_match:
      component: 'api'
    target_match_re:
      alertname: '.*Database.*|.*Connection.*'
    equal: ['instance']

  # If system is under maintenance, suppress infrastructure alerts
  - source_match:
      maintenance: 'true'
    target_match:
      component: 'infrastructure'
    target_match_re:
      severity: 'warning'

# Receiver configurations
receivers:
  # Default receiver
  - name: 'default'
    slack_configs:
      - api_url: '{{ template "slack.default.api_url" . }}'
        channel: '#alerts-general'
        title: 'Aquaculture Platform Alert'
        text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'

  # Critical alerts - all channels
  - name: 'critical-alerts'
    email_configs:
      - to: 'oncall@aquaculture-platform.com'
        subject: 'CRITICAL: {{ .GroupLabels.alertname }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Severity: {{ .Labels.severity }}
          Time: {{ .StartsAt }}
          {{ if .Annotations.runbook_url }}Runbook: {{ .Annotations.runbook_url }}{{ end }}
          {{ if .Annotations.dashboard_url }}Dashboard: {{ .Annotations.dashboard_url }}{{ end }}
          {{ end }}
    slack_configs:
      - api_url: '{{ template "slack.default.api_url" . }}'
        channel: '#alerts-critical'
        title: 'ðŸš¨ CRITICAL ALERT'
        text: |
          {{ range .Alerts }}
          *{{ .Annotations.summary }}*
          {{ .Annotations.description }}
          {{ end }}
        color: 'danger'
    pagerduty_configs:
      - routing_key: 'your-pagerduty-integration-key'
        description: '{{ .GroupLabels.alertname }}'

  # Security team
  - name: 'security-team'
    email_configs:
      - to: 'security@aquaculture-platform.com'
        subject: 'ðŸ”’ Security Alert: {{ .GroupLabels.alertname }}'
        body: |
          {{ range .Alerts }}
          Security Alert: {{ .Annotations.summary }}
          Attack Type: {{ .Labels.attack_type }}
          Description: {{ .Annotations.description }}
          Time: {{ .StartsAt }}
          {{ if .Labels.source_ip }}Source IP: {{ .Labels.source_ip }}{{ end }}
          {{ end }}
    slack_configs:
      - api_url: '{{ template "slack.default.api_url" . }}'
        channel: '#security-alerts'
        title: 'ðŸ”’ Security Alert'
        text: |
          {{ range .Alerts }}
          *{{ .Annotations.summary }}*
          Attack Type: {{ .Labels.attack_type }}
          {{ .Annotations.description }}
          {{ end }}
        color: 'warning'

  # Platform team
  - name: 'platform-team'
    slack_configs:
      - api_url: '{{ template "slack.default.api_url" . }}'
        channel: '#platform-alerts'
        title: 'Platform Alert'
        text: |
          {{ range .Alerts }}
          {{ .Annotations.summary }}
          {{ .Annotations.description }}
          {{ end }}

  # Platform team urgent
  - name: 'platform-team-urgent'
    email_configs:
      - to: 'platform-oncall@aquaculture-platform.com'
        subject: 'URGENT Platform Alert: {{ .GroupLabels.alertname }}'
    slack_configs:
      - api_url: '{{ template "slack.default.api_url" . }}'
        channel: '#platform-urgent'
        title: 'ðŸš¨ Urgent Platform Alert'
        color: 'danger'

  # ML Operations team
  - name: 'ml-ops-team'
    slack_configs:
      - api_url: '{{ template "slack.default.api_url" . }}'
        channel: '#ml-ops-alerts'
        title: 'ML Operations Alert'
        text: |
          {{ range .Alerts }}
          Model: {{ .Labels.model_type }}
          {{ .Annotations.summary }}
          {{ .Annotations.description }}
          {{ end }}

  # ML Ops - Model Performance
  - name: 'ml-ops-team-models'
    email_configs:
      - to: 'ml-team@aquaculture-platform.com'
        subject: 'Model Performance Alert: {{ .GroupLabels.alertname }}'
    slack_configs:
      - api_url: '{{ template "slack.default.api_url" . }}'
        channel: '#ml-model-alerts'
        title: 'ðŸ“Š Model Performance Alert'
        color: 'warning'

  # Operations team
  - name: 'operations-team'
    slack_configs:
      - api_url: '{{ template "slack.default.api_url" . }}'
        channel: '#operations-alerts'
        title: 'Operations Alert'
        text: |
          {{ range .Alerts }}
          KPI: {{ .Labels.kpi }}
          {{ .Annotations.summary }}
          {{ .Annotations.description }}
          {{ end }}

  # Operations urgent
  - name: 'operations-team-urgent'
    email_configs:
      - to: 'operations-oncall@aquaculture-platform.com'
        subject: 'URGENT Operations Alert: {{ .GroupLabels.alertname }}'
    pagerduty_configs:
      - routing_key: 'operations-pagerduty-key'

  # Database team
  - name: 'database-team'
    slack_configs:
      - api_url: '{{ template "slack.default.api_url" . }}'
        channel: '#database-alerts'
        title: 'Database Alert'

  # SLA Management
  - name: 'sla-management'
    email_configs:
      - to: 'management@aquaculture-platform.com'
        subject: 'SLA Breach: {{ .GroupLabels.alertname }}'
        body: |
          SLA Breach Detected
          
          {{ range .Alerts }}
          SLA Type: {{ .Labels.sla_type }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Time: {{ .StartsAt }}
          {{ if .Annotations.dashboard_url }}Dashboard: {{ .Annotations.dashboard_url }}{{ end }}
          {{ end }}

  # Null receiver for maintenance windows
  - name: 'null'



