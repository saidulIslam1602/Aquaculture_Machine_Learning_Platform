# =============================================================================
# MONITORING & OBSERVABILITY - AQUACULTURE PLATFORM HEALTH DASHBOARD
# =============================================================================
#
# WHAT IS THIS DIRECTORY?
# This directory contains the complete monitoring system for the aquaculture platform.
# Think of it as the "mission control center" that watches over every part of the
# system to ensure everything is running smoothly and alerts teams when problems occur.
#
# WHAT IS MONITORING & OBSERVABILITY?
# Monitoring is like having a "health checkup system" for the platform:
# - Metrics: Numerical data about performance (CPU, memory, response times)
# - Logs: Detailed records of what happened and when
# - Traces: Following requests through the entire system
# - Alerts: Automatic notifications when something goes wrong
# - Dashboards: Visual displays showing system health at a glance
#
# WHY IS MONITORING ESSENTIAL?
# In production environments, monitoring is critical because:
# - Early Problem Detection: Catch issues before users notice them
# - Performance Optimization: Identify bottlenecks and slow components
# - Capacity Planning: Know when to scale up resources
# - Troubleshooting: Quickly find the root cause of problems
# - Business Insights: Track important business metrics and KPIs
# - Compliance: Meet regulatory requirements for system monitoring
#
# MONITORING STACK OVERVIEW:
# - Prometheus: Collects and stores performance metrics
# - Grafana: Creates beautiful dashboards and visualizations
# - Alertmanager: Sends notifications when problems are detected
# - ELK Stack: Collects, processes, and searches through logs
# - Jaeger: Tracks requests across multiple services
#
# AUTHOR: DevOps Team
# VERSION: 1.0.0
# UPDATED: 2024-10-26
# =============================================================================

This directory contains a comprehensive, production-ready monitoring and observability stack designed specifically for the Aquaculture ML Platform. The setup includes metrics collection, alerting, log aggregation, distributed tracing, and advanced visualizations.

## üèóÔ∏è Architecture Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Application   ‚îÇ    ‚îÇ   Monitoring    ‚îÇ    ‚îÇ   Alerting      ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ
‚îÇ ‚Ä¢ FastAPI       ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ ‚Ä¢ Prometheus    ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ ‚Ä¢ Alertmanager  ‚îÇ
‚îÇ ‚Ä¢ ML Services   ‚îÇ    ‚îÇ ‚Ä¢ Grafana       ‚îÇ    ‚îÇ ‚Ä¢ PagerDuty     ‚îÇ
‚îÇ ‚Ä¢ Databases     ‚îÇ    ‚îÇ ‚Ä¢ Jaeger        ‚îÇ    ‚îÇ ‚Ä¢ Slack         ‚îÇ
‚îÇ ‚Ä¢ Containers    ‚îÇ    ‚îÇ ‚Ä¢ ELK Stack     ‚îÇ    ‚îÇ ‚Ä¢ Email         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üöÄ Key Features

### Metrics & Monitoring
- **Prometheus**: Advanced metrics collection with 15+ exporters
- **Grafana**: Production-grade dashboards with 50+ panels
- **Custom Metrics**: Business KPIs, ML model performance, security events
- **Multi-dimensional Alerting**: 100+ alert rules across 6 categories

### Log Management
- **ELK Stack**: Centralized logging with Elasticsearch, Logstash, Kibana
- **Structured Logging**: JSON-formatted logs with enrichment
- **Log Parsing**: Intelligent parsing for API, ML, security, and business logs
- **Real-time Analysis**: Live log streaming and analysis

### Distributed Tracing
- **Jaeger**: Request tracing across microservices
- **Performance Insights**: Latency analysis and bottleneck identification
- **Error Correlation**: Link traces to logs and metrics

### Kubernetes Integration
- **ServiceMonitor**: Automatic service discovery
- **PrometheusRules**: Kubernetes-native alerting
- **Pod Monitoring**: Container-level metrics and health checks

## üìä Monitoring Components

### Core Stack
| Component | Version | Purpose | Port |
|-----------|---------|---------|------|
| Prometheus | 2.48.0 | Metrics collection | 9090 |
| Grafana | 10.2.2 | Visualization | 3000 |
| Alertmanager | 0.26.0 | Alert routing | 9093 |
| Jaeger | 1.51 | Distributed tracing | 16686 |

### Exporters
| Exporter | Purpose | Port |
|----------|---------|------|
| Node Exporter | System metrics | 9100 |
| cAdvisor | Container metrics | 8080 |
| Postgres Exporter | Database metrics | 9187 |
| Redis Exporter | Cache metrics | 9121 |

### ELK Stack
| Component | Version | Purpose | Port |
|-----------|---------|---------|------|
| Elasticsearch | 8.11.0 | Search & analytics | 9200 |
| Logstash | 8.11.0 | Log processing | 5044 |
| Kibana | 8.11.0 | Log visualization | 5601 |
| Filebeat | 8.11.0 | Log shipping | 5066 |

## üîß Quick Start

### Prerequisites
- Docker & Docker Compose
- 8GB+ RAM recommended
- 20GB+ disk space

### 1. Basic Deployment
```bash
# Deploy core monitoring stack
./scripts/deploy-monitoring.sh

# Access services
open http://localhost:3000  # Grafana (admin/admin)
open http://localhost:9090  # Prometheus
open http://localhost:9093  # Alertmanager
```

### 2. Full Stack Deployment
```bash
# Deploy everything (monitoring + ELK + K8s)
./scripts/deploy-monitoring.sh --full

# Additional services
open http://localhost:5601  # Kibana
open http://localhost:16686 # Jaeger
```

### 3. Manual Deployment
```bash
# Core monitoring
docker-compose up -d prometheus grafana alertmanager

# ELK stack
cd monitoring/elk
docker-compose -f docker-compose-elk.yml up -d

# Kubernetes (if available)
kubectl apply -f infrastructure/kubernetes/
```

## üìà Dashboards

### System Overview Dashboard
- **Real-time Metrics**: API throughput, response times, error rates
- **Infrastructure Health**: CPU, memory, disk usage across all nodes
- **Business KPIs**: Fish mortality, water quality, production metrics
- **Alert Status**: Active alerts with severity levels

### ML Performance Dashboard
- **Model Accuracy**: Real-time accuracy tracking for all models
- **Inference Latency**: P50, P95, P99 latency distributions
- **Model Drift**: Drift detection scores and trends
- **Resource Usage**: GPU utilization, memory consumption
- **Training Metrics**: Training duration, success/failure rates

### Security Dashboard
- **Authentication Events**: Login attempts, failures, suspicious activity
- **API Security**: Rate limiting, unauthorized access attempts
- **Network Security**: Traffic patterns, potential attacks
- **Compliance Metrics**: Security score, audit events

## üö® Alerting

### Alert Categories
1. **API Alerts**: Availability, latency, error rates
2. **Infrastructure**: CPU, memory, disk, network
3. **ML Models**: Accuracy degradation, drift detection
4. **Business KPIs**: Mortality rates, water quality, production
5. **Security**: Suspicious activity, authentication failures
6. **SLA Monitoring**: Availability, performance, error budgets

### Alert Routing
- **Critical**: PagerDuty + Slack + Email (immediate)
- **Warning**: Slack + Email (5-15 min delay)
- **Info**: Slack only (30+ min delay)

### Sample Alerts
```yaml
# High API Error Rate
- alert: HighErrorRate
  expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.05
  for: 2m
  severity: warning

# Model Accuracy Drop
- alert: ModelAccuracyDrop
  expr: model_prediction_accuracy < 0.85
  for: 10m
  severity: warning

# High Fish Mortality
- alert: HighMortalityRate
  expr: business_fish_mortality_rate > 0.05
  for: 15m
  severity: critical
```

## üìù Log Management

### Log Sources
- **Application Logs**: FastAPI, ML services, workers
- **System Logs**: Syslog, auth logs, kernel logs
- **Container Logs**: Docker container stdout/stderr
- **Database Logs**: PostgreSQL slow queries, errors
- **Security Logs**: Authentication, authorization events

### Log Processing Pipeline
1. **Collection**: Filebeat collects from multiple sources
2. **Processing**: Logstash parses, enriches, and transforms
3. **Storage**: Elasticsearch indexes with daily rotation
4. **Visualization**: Kibana provides search and dashboards

### Index Strategy
```
aquaculture-api-2024.01.15      # API logs
aquaculture-ml-2024.01.15       # ML service logs
aquaculture-business-2024.01.15 # Business metrics
aquaculture-security-2024.01.15 # Security events
aquaculture-errors-2024.01.15   # Error logs
```

## üîç Distributed Tracing

### Jaeger Integration
- **Request Tracing**: End-to-end request flow
- **Service Dependencies**: Visual service map
- **Performance Analysis**: Latency breakdown by service
- **Error Correlation**: Link errors to specific traces

### Trace Context
```json
{
  "trace_id": "abc123...",
  "span_id": "def456...",
  "operation": "ml_prediction",
  "service": "aquaculture-ml",
  "duration": "245ms",
  "tags": {
    "model_type": "fish_classification",
    "accuracy": 0.94
  }
}
```

## üéØ Business Metrics

### Key Performance Indicators (KPIs)
- **Fish Health**: Mortality rate, growth rate, health scores
- **Water Quality**: pH, oxygen, temperature, turbidity
- **Production**: Daily yield, feed conversion ratio
- **Efficiency**: Energy consumption, operational costs
- **Quality**: Product grade, customer satisfaction

### Custom Metrics Collection
```python
# Business metrics in FastAPI
from utils.metrics import performance_metrics

# Record fish mortality
performance_metrics.record_business_metric(
    'mortality_rate', 
    0.02, 
    {'tank_id': 'tank_001', 'species': 'salmon'}
)

# Record water quality
performance_metrics.record_business_metric(
    'water_quality_score', 
    0.95, 
    {'tank_id': 'tank_001', 'parameter': 'oxygen'}
)
```

## üîí Security Monitoring

### Security Events Tracked
- **Authentication**: Login attempts, failures, lockouts
- **Authorization**: Permission denials, privilege escalation
- **API Security**: Rate limiting, suspicious patterns
- **Data Access**: Sensitive data queries, exports
- **Network**: Unusual traffic, potential attacks

### Security Dashboards
- **Real-time Threats**: Active security events
- **User Behavior**: Authentication patterns, anomalies
- **API Security**: Rate limiting effectiveness, blocked requests
- **Compliance**: Security score, audit trail

## üöÄ Performance Optimization

### High-Volume Metrics
- **Scrape Intervals**: 15s for API, 30s for infrastructure
- **Retention**: 30 days local, long-term remote storage
- **Compression**: TSDB compression enabled
- **Sharding**: Multiple Prometheus instances for scale

### Resource Requirements
```yaml
# Minimum requirements
CPU: 4 cores
Memory: 8GB RAM
Disk: 100GB SSD

# Recommended for production
CPU: 8 cores
Memory: 16GB RAM
Disk: 500GB SSD
Network: 1Gbps
```

## üîß Configuration

### Environment Variables
```bash
# Prometheus
PROMETHEUS_RETENTION_TIME=30d
PROMETHEUS_RETENTION_SIZE=10GB

# Grafana
GF_SECURITY_ADMIN_PASSWORD=secure_password
GF_INSTALL_PLUGINS=grafana-piechart-panel

# Elasticsearch
ES_JAVA_OPTS=-Xms2g -Xmx2g
```

### Custom Configuration Files
- `prometheus/prometheus.yml`: Scrape configuration
- `alertmanager/alertmanager.yml`: Alert routing
- `grafana/provisioning/`: Dashboards and datasources
- `elk/logstash/pipeline/`: Log processing rules

## üìö Troubleshooting

### Common Issues

#### Prometheus Not Scraping
```bash
# Check target status
curl http://localhost:9090/api/v1/targets

# Verify service discovery
kubectl get servicemonitor -n aquaculture-prod
```

#### High Memory Usage
```bash
# Check Prometheus memory
docker stats aquaculture-prometheus

# Reduce retention if needed
--storage.tsdb.retention.time=15d
```

#### Elasticsearch Issues
```bash
# Check cluster health
curl http://localhost:9200/_cluster/health

# Check indices
curl http://localhost:9200/_cat/indices
```

### Health Checks
```bash
# All services health
./scripts/health-check.sh

# Individual services
curl http://localhost:9090/-/healthy    # Prometheus
curl http://localhost:3000/api/health   # Grafana
curl http://localhost:9093/-/healthy    # Alertmanager
```

## üîÑ Maintenance

### Regular Tasks
- **Weekly**: Review alert noise, update dashboards
- **Monthly**: Clean old logs, update retention policies
- **Quarterly**: Review metrics cardinality, optimize queries

### Backup Strategy
```bash
# Prometheus data
docker exec aquaculture-prometheus promtool tsdb create-blocks-from-rules

# Grafana dashboards
curl -H "Authorization: Bearer $API_KEY" \
  http://localhost:3000/api/dashboards/export
```

## üìû Support

### Runbooks
- [API Outage Response](runbooks/api-outage.md)
- [High Error Rate Investigation](runbooks/high-error-rate.md)
- [Model Performance Degradation](runbooks/model-degradation.md)
- [Security Incident Response](runbooks/security-incident.md)

### Contacts
- **Platform Team**: platform-team@aquaculture.com
- **ML Ops Team**: ml-ops@aquaculture.com
- **Security Team**: security@aquaculture.com
- **On-call**: +1-555-ONCALL

---

## üéØ Telenor Alignment

This monitoring setup specifically addresses Telenor's observability requirements:

### Technology Stack Match
‚úÖ **Prometheus**: Advanced metrics collection and alerting  
‚úÖ **Grafana**: Rich visualization and dashboarding  
‚úÖ **Kubernetes**: Cloud-native monitoring with ServiceMonitors  
‚úÖ **ELK Stack**: Centralized logging and analysis  
‚úÖ **Jaeger**: Distributed tracing for microservices  
‚úÖ **Docker**: Containerized deployment  

### Operational Excellence
‚úÖ **High Availability**: Multi-instance, health checks  
‚úÖ **Scalability**: Horizontal scaling, sharding support  
‚úÖ **Security**: Authentication, authorization, audit trails  
‚úÖ **Automation**: Infrastructure as Code, CI/CD integration  
‚úÖ **Observability**: Full-stack visibility, SLA monitoring  

### Production Readiness
‚úÖ **Alerting**: 100+ production-grade alert rules  
‚úÖ **Dashboards**: Comprehensive visualization suite  
‚úÖ **Documentation**: Detailed runbooks and procedures  
‚úÖ **Monitoring**: Self-monitoring and health checks  
‚úÖ **Performance**: Optimized for high-volume environments  

This implementation demonstrates enterprise-grade observability practices that would be directly applicable to Telenor's infrastructure monitoring and data insight requirements.



