# Logstash Pipeline Configuration for Aquaculture ML Platform
# Processes logs from various sources and enriches them for analysis

input {
  # Beats input (Filebeat, Metricbeat)
  beats {
    port => 5044
  }

  # TCP input for application logs
  tcp {
    port => 5000
    codec => json_lines
  }

  # UDP input for syslog
  udp {
    port => 5000
    codec => json_lines
  }

  # HTTP input for webhook logs
  http {
    port => 8080
    codec => json
  }
}

filter {
  # Parse timestamp
  if [timestamp] {
    date {
      match => [ "timestamp", "ISO8601" ]
    }
  }

  # Docker container logs processing
  if [container] {
    mutate {
      add_field => { "log_source" => "docker" }
    }
    
    # Extract container information
    if [container][name] {
      mutate {
        add_field => { "service_name" => "%{[container][name]}" }
      }
    }
  }

  # FastAPI application logs
  if [logger_name] =~ /^uvicorn/ or [logger_name] =~ /^fastapi/ {
    mutate {
      add_field => { "log_type" => "api" }
      add_field => { "component" => "api" }
    }

    # Parse HTTP request logs
    if [message] =~ /^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}/ {
      grok {
        match => { 
          "message" => "%{IPORHOST:client_ip} - - \[%{HTTPDATE:request_timestamp}\] \"%{WORD:http_method} %{URIPATH:request_path}(?:%{URIPARAM:request_params})? HTTP/%{NUMBER:http_version}\" %{NUMBER:response_code} %{NUMBER:response_size}" 
        }
      }
      
      # Convert response code to integer
      mutate {
        convert => { "response_code" => "integer" }
        convert => { "response_size" => "integer" }
      }
      
      # Add response status category
      if [response_code] >= 200 and [response_code] < 300 {
        mutate { add_field => { "response_status" => "success" } }
      } else if [response_code] >= 300 and [response_code] < 400 {
        mutate { add_field => { "response_status" => "redirect" } }
      } else if [response_code] >= 400 and [response_code] < 500 {
        mutate { add_field => { "response_status" => "client_error" } }
      } else if [response_code] >= 500 {
        mutate { add_field => { "response_status" => "server_error" } }
      }
    }
  }

  # ML Service logs
  if [logger_name] =~ /ml_service/ or [service_name] =~ /ml/ {
    mutate {
      add_field => { "log_type" => "ml" }
      add_field => { "component" => "ml" }
    }

    # Parse model prediction logs
    if [message] =~ /prediction/ {
      grok {
        match => { 
          "message" => "Model prediction: model=%{WORD:model_name}, accuracy=%{NUMBER:prediction_accuracy}, latency=%{NUMBER:prediction_latency}ms" 
        }
      }
      
      mutate {
        convert => { "prediction_accuracy" => "float" }
        convert => { "prediction_latency" => "float" }
      }
    }

    # Parse model training logs
    if [message] =~ /training/ {
      grok {
        match => { 
          "message" => "Model training: model=%{WORD:model_name}, epoch=%{NUMBER:epoch}, loss=%{NUMBER:training_loss}, accuracy=%{NUMBER:training_accuracy}" 
        }
      }
      
      mutate {
        convert => { "epoch" => "integer" }
        convert => { "training_loss" => "float" }
        convert => { "training_accuracy" => "float" }
      }
    }
  }

  # Database logs
  if [logger_name] =~ /database/ or [service_name] =~ /postgres/ {
    mutate {
      add_field => { "log_type" => "database" }
      add_field => { "component" => "database" }
    }

    # Parse slow query logs
    if [message] =~ /slow query/ {
      grok {
        match => { 
          "message" => "Slow query detected: duration=%{NUMBER:query_duration}ms, query=%{GREEDYDATA:sql_query}" 
        }
      }
      
      mutate {
        convert => { "query_duration" => "float" }
      }
    }
  }

  # Security logs
  if [logger_name] =~ /security/ or [message] =~ /security/ {
    mutate {
      add_field => { "log_type" => "security" }
      add_field => { "component" => "security" }
    }

    # Parse authentication logs
    if [message] =~ /authentication/ {
      grok {
        match => { 
          "message" => "Authentication %{WORD:auth_result}: user=%{WORD:username}, ip=%{IPORHOST:client_ip}, method=%{WORD:auth_method}" 
        }
      }
    }

    # Parse suspicious activity logs
    if [message] =~ /suspicious/ {
      grok {
        match => { 
          "message" => "Suspicious activity detected: type=%{WORD:activity_type}, ip=%{IPORHOST:client_ip}, details=%{GREEDYDATA:activity_details}" 
        }
      }
      
      mutate {
        add_field => { "alert_level" => "high" }
      }
    }
  }

  # Business metrics logs
  if [logger_name] =~ /business/ or [message] =~ /business/ {
    mutate {
      add_field => { "log_type" => "business" }
      add_field => { "component" => "business" }
    }

    # Parse KPI logs
    if [message] =~ /kpi/ {
      grok {
        match => { 
          "message" => "KPI update: metric=%{WORD:kpi_name}, value=%{NUMBER:kpi_value}, tank_id=%{WORD:tank_id}" 
        }
      }
      
      mutate {
        convert => { "kpi_value" => "float" }
      }
    }
  }

  # Error logs processing
  if [level] == "ERROR" or [log_level] == "ERROR" {
    mutate {
      add_field => { "is_error" => "true" }
      add_field => { "alert_required" => "true" }
    }

    # Extract stack trace if present
    if [message] =~ /Traceback/ {
      mutate {
        add_field => { "has_stacktrace" => "true" }
      }
    }
  }

  # Performance logs
  if [message] =~ /performance/ or [message] =~ /latency/ {
    mutate {
      add_field => { "log_type" => "performance" }
    }
  }

  # Add geolocation for IP addresses
  if [client_ip] and [client_ip] !~ /^(10\.|172\.(1[6-9]|2[0-9]|3[01])\.|192\.168\.|127\.)/ {
    geoip {
      source => "client_ip"
      target => "geoip"
    }
  }

  # Enrich with environment information
  mutate {
    add_field => { 
      "environment" => "production"
      "platform" => "aquaculture-ml"
      "ingestion_timestamp" => "%{@timestamp}"
    }
  }

  # Clean up fields
  mutate {
    remove_field => [ "host", "agent", "ecs", "input", "log" ]
  }
}

output {
  # Output to Elasticsearch with dynamic indexing
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    
    # Dynamic index based on log type and date
    index => "aquaculture-%{[log_type]:unknown}-%{+YYYY.MM.dd}"
    
    # Document type
    document_type => "_doc"
    
    # Template for index settings
    template_name => "aquaculture"
    template => "/usr/share/logstash/templates/aquaculture-template.json"
    template_overwrite => true
  }

  # Output errors to separate index
  if [is_error] == "true" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "aquaculture-errors-%{+YYYY.MM.dd}"
      document_type => "_doc"
    }
  }

  # Output security events to separate index
  if [log_type] == "security" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "aquaculture-security-%{+YYYY.MM.dd}"
      document_type => "_doc"
    }
  }

  # Output business metrics to separate index
  if [log_type] == "business" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "aquaculture-business-%{+YYYY.MM.dd}"
      document_type => "_doc"
    }
  }

  # Debug output (comment out in production)
  # stdout { 
  #   codec => rubydebug 
  # }
}
