# =============================================================================
# ELK STACK CONFIGURATION - AQUACULTURE PLATFORM CENTRALIZED LOGGING
# =============================================================================
#
# WHAT IS THIS FILE?
# This Docker Compose file sets up the ELK Stack (Elasticsearch, Logstash, Kibana)
# for centralized logging. Think of it as creating a "log analysis center" that
# collects, processes, and visualizes all logs from the aquaculture platform.
#
# WHAT IS THE ELK STACK?
# ELK is a powerful logging solution consisting of three components:
# - Elasticsearch: Stores and searches through log data (like a smart database)
# - Logstash: Processes and transforms log data before storing it
# - Kibana: Provides web interface for searching and visualizing logs
#
# WHY USE ELK FOR LOGGING?
# Centralized logging is essential because:
# - Multiple services generate logs (API, ML, worker, database)
# - Logs help troubleshoot problems and understand system behavior
# - ELK makes it easy to search through millions of log entries
# - Kibana provides dashboards to visualize trends and patterns
# - Helps with compliance and audit requirements
#
# HOW ELK WORKS TOGETHER:
# 1. Applications send logs to Logstash (or directly to Elasticsearch)
# 2. Logstash processes, filters, and enriches the log data
# 3. Processed logs are stored in Elasticsearch for fast searching
# 4. Kibana provides web interface to search, analyze, and visualize logs
# 5. Users can create dashboards, alerts, and reports from log data
#
# AUTHOR: DevOps Team
# VERSION: 1.0.0
# UPDATED: 2024-10-26
# =============================================================================

version: '3.8'

# =============================================================================
# ELK STACK SERVICES - LOGGING INFRASTRUCTURE COMPONENTS
# =============================================================================

services:
  # =============================================================================
  # ELASTICSEARCH - LOG STORAGE AND SEARCH ENGINE
  # =============================================================================
  # Elasticsearch stores all log data and provides fast search capabilities
  
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0  # Official Elasticsearch image
    container_name: aquaculture-elasticsearch                    # Container name for easy reference
    
    # Elasticsearch configuration through environment variables
    environment:
      - node.name=elasticsearch                    # Node name in the cluster
      - cluster.name=aquaculture-cluster          # Cluster name for this deployment
      - discovery.type=single-node                # Single node setup (for development/small deployments)
      - bootstrap.memory_lock=true                # Lock memory to prevent swapping (improves performance)
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"             # Java heap size (2GB min/max for log storage)
      - xpack.security.enabled=false              # Disable security for development (enable in production)
      - xpack.security.enrollment.enabled=false   # Disable automatic enrollment
      - xpack.security.http.ssl.enabled=false     # Disable HTTPS (enable in production)
      - xpack.security.transport.ssl.enabled=false # Disable transport SSL
      - action.destructive_requires_name=false    # Allow index deletion without explicit names
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
      - ./elk/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      - elk-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Logstash - Data Processing Pipeline
  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    container_name: aquaculture-logstash
    environment:
      - "LS_JAVA_OPTS=-Xmx1g -Xms1g"
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    volumes:
      - ./elk/logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
      - ./elk/logstash/pipeline:/usr/share/logstash/pipeline:ro
      - ./elk/logstash/patterns:/usr/share/logstash/patterns:ro
    ports:
      - "5044:5044"  # Beats input
      - "5000:5000/tcp"  # TCP input
      - "5000:5000/udp"  # UDP input
      - "9600:9600"  # Logstash monitoring API
    depends_on:
      - elasticsearch
    networks:
      - elk-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9600 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Kibana - Data Visualization and Exploration
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: aquaculture-kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - SERVER_NAME=kibana
      - SERVER_HOST=0.0.0.0
      - XPACK_SECURITY_ENABLED=false
      - XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY=a7a6311933d3503b89bc2dbc36572c33a6c10925682e591bffcab6911c06786d
    volumes:
      - ./elk/kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml:ro
      - kibana_data:/usr/share/kibana/data
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    networks:
      - elk-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5601/api/status || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Filebeat - Log Shipper
  filebeat:
    image: docker.elastic.co/beats/filebeat:8.11.0
    container_name: aquaculture-filebeat
    user: root
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - LOGSTASH_HOSTS=logstash:5044
    volumes:
      - ./elk/filebeat/config/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/log:/var/log:ro
      - filebeat_data:/usr/share/filebeat/data
    command: filebeat -e -strict.perms=false
    depends_on:
      - elasticsearch
      - logstash
    networks:
      - elk-network
    restart: unless-stopped

  # Metricbeat - System and Service Metrics
  metricbeat:
    image: docker.elastic.co/beats/metricbeat:8.11.0
    container_name: aquaculture-metricbeat
    user: root
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    volumes:
      - ./elk/metricbeat/config/metricbeat.yml:/usr/share/metricbeat/metricbeat.yml:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro
      - /proc:/hostfs/proc:ro
      - /:/hostfs:ro
      - metricbeat_data:/usr/share/metricbeat/data
    command: metricbeat -e -strict.perms=false -system.hostfs=/hostfs
    depends_on:
      - elasticsearch
    networks:
      - elk-network
    restart: unless-stopped

  # APM Server - Application Performance Monitoring
  apm-server:
    image: docker.elastic.co/apm/apm-server:8.11.0
    container_name: aquaculture-apm-server
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    volumes:
      - ./elk/apm-server/config/apm-server.yml:/usr/share/apm-server/apm-server.yml:ro
    ports:
      - "8200:8200"
    depends_on:
      - elasticsearch
    networks:
      - elk-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8200 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

volumes:
  elasticsearch_data:
    driver: local
  kibana_data:
    driver: local
  filebeat_data:
    driver: local
  metricbeat_data:
    driver: local

networks:
  elk-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
